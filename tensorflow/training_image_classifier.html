<!DOCTYPE html><html lang="en"><head><title>Training your own image classifier with TensorFlow by Scott Thompson</title><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css"><link rel="stylesheet" href="http://code.jquery.com/ui/1.11.4/themes/ui-lightness/jquery-ui.css"/><script src="http://code.jquery.com/jquery-2.1.4.min.js"></script><script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="../js/jquery-ui.js"></script><script src="../js/player.js"></script><script>if (document.location.hostname.search('videojots.com') !== -1) {(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create', 'UA-78294929-1', 'auto');ga('send', 'pageview');}</script><style>#segrip {width: 10px;height: 10px;background-color: #ffffff;border: 1px solid #000000;bottom: -5px;right: -5px;}</style></head><body><div style="margin: 0 auto;width:70%" ><div id="videoid" style="visibility: hidden">VpDonQAKtE4</div><br/><ol class="breadcrumb"><li><a href="../">Home</a></li><li><a href="./" class="category">TensorFlow</a></li><li class="active">Training your own image classifier with TensorFlow by Scott Thompson</li></ol><div style=""><span class="videojots"><br/><span class="label label-danger">Click on text below to jump to the corresponding location in the video (except iOS)</span><br/><div id="control"><div id="playerBox"><div class="ui-resizable-handle ui-resizable-se" id="segrip"></div><div id="videoPlayer"></div></div><div class="TensorFlow" id="adVpDonQAKtE4"></div></div><br/><br/><style scoped>.clickable{cursor:pointer;cursor:hand;}.clickable:hover{background:yellow;} .t{font-weight:bold;}.t:before{content:"\A";white-space: pre;}.t:after{content:"\A";white-space: pre;}</style><div  class="resizable"><br/><span class="clickable" id="5.639">I am Scott. </span><span class="clickable" id="7.259">I am a software engineer in NYC at Kontor which is like a place for office design. </span><span class="clickable" id="17.16">I am here to talk to you about one of my side projects - a visual search and classification engine for Gilt. </span><span class="clickable" id="29.772">Gilt is a large ecommerce site with products like sunglasses, dresses, shoes. </span><span class="clickable" id="44.732">This talk is geared towards software engineers. </span><span class="clickable" id="72.481"><br/>There has been a lot of engineering effort put into TensorFlow, how to productionize it. </span><span class="clickable" id="82.166">I will touch on the theory but focus on the engineering around TensorFlow. </span><span class="clickable" id="86.378"><br/><span class="t">Classification</span></span><span class="clickable" id="94.628">The basic problem - I take a selfie - and need labels for the shirt, descending by what is most likely in the image. </span><span class="clickable" id="128.133">I want the labels to be from the Gilt taxonomy. </span><span class="clickable" id="131.076"><br/><span class="t">Visual search</span></span><span class="clickable" id="137.078">Given the image, I want to search the Gilt catalog for other short sleeved sports shirts. </span><span class="clickable" id="150.464"><br/><span class="t">How to distill the essence of an image?</span></span><span class="clickable" id="152.57">We want to distill the essence - a machine readable vector of numbers that represent this image. </span><span class="clickable" id="168.619">The reason is there are a lot of well known algorithms which can run on this, like classification and they all require some kind of input format which is a vector of numbers. </span><span class="clickable" id="189.439"><br/>I can run two kinds of algorithms - classification and nearest neighbor search. </span><span class="clickable" id="198.431">I want to spend time on how to get the essence of the image - construct the features of the image. </span><span class="clickable" id="201.906">Once we can do that, all these other algorithms depend on having good features for the image. </span><span class="clickable" id="207.855"><br/><span class="t">Image features</span></span><span class="clickable" id="210.325">I could download OpenCV, a library for processing images and start handcrafting features. </span><span class="clickable" id="217.558">I could do some edge detection, pick out boundaries around shapes, put those into a vector to get rid of a lot of noise. </span><span class="clickable" id="232.199">I could make a color histogram. </span><span class="clickable" id="239.199">The problem with all this is that there is a lot of process involved with coming up with all these hand-crafted features. </span><span class="clickable" id="243.84">A random forest could tell me which features are more predictive than others for example but a lot of effort and engineering has to go into just selecting the features. </span><span class="clickable" id="261.634"><br/><span class="t">Convolutional neural nets</span></span><span class="clickable" id="264.899">Provide a black box to construct these features that I normally would have had to hand-craft. </span><span class="clickable" id="279.895">If I want to use a convolutional neural network, to train it, typically lots of time and effort and GPU farm to do in a reasonable amount of time. </span><span class="clickable" id="304.506">Luckily, the TensorFlow team has released a pre-trained model, the Inception-v3, which has already been trained on a dataset called ImageNet. </span><span class="clickable" id="313.817">It does a really good job of classifying images. </span><span class="clickable" id="317.603"><br/><span class="t">ImageNet</span></span><span class="clickable" id="322.352">Broad set of images across many categories. </span><span class="clickable" id="350.352"><br/><span class="t">Why use a pre-trained model?</span></span><span class="clickable" id="352.742">Its is faster, it is cheap and it generalizes (most important)</span><span class="clickable" id="393.74"><br/><span class="t">Transfer learning</span></span><span class="clickable" id="396.35">We have the inception v3 model. </span><span class="clickable" id="396.351">We know the model has been trained on ImageNet, it hasn't seen any Gilt images before. </span><span class="clickable" id="411.724">I want to know specific taxonomy for the data I am interested in. </span><span class="clickable" id="420.876">We will apply this technique called transfer learning. </span><span class="clickable" id="430.146"><br/><span class="t">Structure of the network</span></span><span class="clickable" id="441.646">Let us look at a convolutional neural network. </span><span class="clickable" id="445.665">There are lots of layers to this network. </span><span class="clickable" id="451.304">Images will come in from the left side and out on the right side will come a label and a probability associated with that label. </span><span class="clickable" id="456.548">If you inspect the earlier layers in the network, you will notice some interesting things. </span><span class="clickable" id="464.079">It is teaching itself an edge detector. </span><span class="clickable" id="479.288">If you traverse a little farther, it is picking up more and more specific things in the image. </span><span class="clickable" id="487.325">You might see a shape detector as you go further down this network. </span><span class="clickable" id="491.741">At the very end, is the essence of our image. </span><span class="clickable" id="511.998">If we chop the last couple of layers off, what we are left with is a generalized image recognition blackbox which is exactly what we want to use. </span><span class="clickable" id="525.106"><br/><span class="t">t-SNE plot</span></span><span class="clickable" id="528.767">How do we know if we will actually get something useful if we chop these final layers off? </span><span class="clickable" id="535.264">There is a cool algorithm called t-SNE which you can feed a bunch of images through your neural net, get all these features off the second last layer of your neural network and you can plot them. </span><span class="clickable" id="552.925">You can use t-SNE to reduce the dimension of these feature vectors into 2D space - once you have it in 2D space it is easy to plot them. </span><span class="clickable" id="569.624">In this case, I ran on CIFAR 10 data set and this is what came out. </span><span class="clickable" id="579.671">The yellow cluster at the top represents an image of a car and it clusters nicely. </span><span class="clickable" id="591.64">The orange cluster is trucks. </span><span class="clickable" id="607.896">Reds are cats and grays are dogs. </span><span class="clickable" id="615.702">It has some trouble sifting out between cat and dog but does a pretty good job. </span><span class="clickable" id="631.126">So t-SNE gives you a great way to get a sense of the features you are extracting from your images. </span><span class="clickable" id="635.478"><br/><span class="t">Code demo</span></span><span class="clickable" id="658.977">-load the inception-v3 file</span><span class="clickable" id="669.779"><br/>-get a reference to the pool 3 layer</span><span class="clickable" id="683.488"><br/>-extract features for your own image</span><span class="clickable" id="733.976"><br/><span class="t">Performance</span></span><span class="clickable" id="748.976">On average, it takes a second per image. </span><span class="clickable" id="760.726">It will take about 12 hours for this case. </span><span class="clickable" id="783.477">It is an easily parallelizable problem though. </span><span class="clickable" id="804.232">I would recommend - if you extract pool_3 features then save them somewhere. </span><span class="clickable" id="809.316">I save them as numpy array in a postgres database. </span><span class="clickable" id="817.112"><br/><span class="t">Applying pool_3 features</span></span><span class="clickable" id="846.119">We can do the nearest neighbor search - I ran a brute force search. </span><span class="clickable" id="868.868">For a large dataset, the approximate nearest neighbor search could be a good choice. </span><span class="clickable" id="894.127"><br/>Finally I want to train a classifier. </span><span class="clickable" id="907.369">I used Nearest Neighbor classifier, but you could just as well use Softmax classifier. </span><span class="clickable" id="916.662"><br/><span class="t">You don't need to use TensorFlow for everything</span></span><span class="clickable" id="934.911">Many of the stuff mentioned in the TensorFlow tutorials are not essential, and you can customize it to suit your problem. </span><span class="clickable" id="980.52"><br/><span class="t">Output demo</span></span><span class="clickable" id="1148.421"><span class="t">Q&amp;A</span></span><br/><span style="font-size:xx-small;">Video outline created using <a href="http://www.videojots.com">VideoJots</a>. Click and drag lower right corner to resize video. On <a href="../ios_device.html">iOS devices</a> you cannot jump to video location by clicking on the outline. </span><br/></div></span></div></div></body></html>