{"text":"[{\"pos\":7156,\"text\":\"Welcome to Spark Summit 2016. \"},{\"pos\":8964,\"text\":\"This is our largest Spark summit yet. \"},{\"pos\":35842,\"text\":\"Spark 2.0 is the next major release of the project. \"},{\"pos\":39060,\"text\":\"It comes out later this month. \"},{\"pos\":91316,\"text\":\"It remains highly compatible with 1.x. \"},{\"pos\":138953,\"text\":\"Spark 2.0 is our largest release yet. \"},{\"pos\":153199,\"text\":\"<span class=\\\"t\\\">Apache Spark philosophy</span>\"},{\"pos\":168639,\"text\":\"1. Offers a unified engine that supports many different types of applications. \"},{\"pos\":191498,\"text\":\"We want users to build end to end applications. \"},{\"pos\":202520,\"text\":\"/n/2. High level APIs - easy to use system. \"},{\"pos\":212956,\"text\":\"Such APIs also allow rich optimizations. \"},{\"pos\":217283,\"text\":\"/n/3. Integrate broadly - agnostic to storage systems, integrates with many libraries. \"},{\"pos\":249503,\"text\":\"<span class=\\\"t\\\">New in 2.0</span>\"},{\"pos\":269510,\"text\":\"Structured API improvements - new set of APIs. \"},{\"pos\":291276,\"text\":\"Give the engine more information about your data and let it do much richer optimizations. \"},{\"pos\":312322,\"text\":\"/n/Structured streaming - early on. \"},{\"pos\":320551,\"text\":\"High level streaming API. \"},{\"pos\":332928,\"text\":\"/n/MLLib model export - being able to export models and pipelines and use them in other programs. \"},{\"pos\":345664,\"text\":\"/n/MLLib R bindings have been greatly improved. \"},{\"pos\":349566,\"text\":\"/n/SQL 2003 is now supported. \"},{\"pos\":361420,\"text\":\"/n/Scala 2.12 support\"},{\"pos\":374511,\"text\":\"/n/Broader community:\"},{\"pos\":382628,\"text\":\"/n/Deep learning libraries\"},{\"pos\":409873,\"text\":\"/n/GraphFrames\"},{\"pos\":417995,\"text\":\"/n/PyData\"},{\"pos\":420413,\"text\":\"/n/Reactive streams, C# bindings, JS bindings\"},{\"pos\":440046,\"text\":\"/n/This works builds on common interface of RDDs and DataFrames\"},{\"pos\":465782,\"text\":\"<span class=\\\"t\\\">Deep dive: Structured APIs</span>\"},{\"pos\":487011,\"text\":\"The first is the DataFrame APIs modeled after R dataframes and pandas. \"},{\"pos\":498331,\"text\":\"It lets you access data from a variety of datasources. \"},{\"pos\":510549,\"text\":\"Then you can do DB like operations on the data. \"},{\"pos\":543173,\"text\":\"/n/The engine then optimizes them in the same way a database optimizes a query plan. \"},{\"pos\":573311,\"text\":\"/n/On top of that, we also get very efficient execution. \"},{\"pos\":606150,\"text\":\"<span class=\\\"t\\\">New in 2.0</span>\"},{\"pos\":612379,\"text\":\"Whole stage code generation - which can optimize across multiple operators like I showed before. \"},{\"pos\":622233,\"text\":\"Can give high speedups. \"},{\"pos\":626586,\"text\":\"/n/Also much faster input/output from Apache Parquet and built-in cache. \"},{\"pos\":635666,\"text\":\"<span class=\\\"t\\\">Structured streaming</span>\"},{\"pos\":640942,\"text\":\"High level streaming API which is built on DataFrames. \"},{\"pos\":644482,\"text\":\"It includes higher level features like working with event time, windowing, sessions, support for many sources and sinks\"},{\"pos\":658782,\"text\":\"/n/Also support interactive and batch queries on the same data in a consistent fashion. This is the most common use case in streaming. \"},{\"pos\":690923,\"text\":\"/n/Aggregate data in a stream, then serve it using JDBS\"},{\"pos\":697643,\"text\":\"/n/Change queries at runtime\"},{\"pos\":701411,\"text\":\"/n/Build and apply ML models\"},{\"pos\":707493,\"text\":\"/n/Not just streaming, but continuous applications\"},{\"pos\":733306,\"text\":\"<span class=\\\"t\\\">Structured Streaming API</span>\"},{\"pos\":744362,\"text\":\"All the streaming APIs are very complex. \"},{\"pos\":751804,\"text\":\"We had static dataframes in 1.x. \"},{\"pos\":762676,\"text\":\"In 2.0, we just had infinite dataframes. \"},{\"pos\":778044,\"text\":\"The engine will turn it into an incremental execution plan when you have the infinite dataframe. \"},{\"pos\":783450,\"text\":\"<span class=\\\"t\\\">Example: Batch App</span>\"},{\"pos\":821603,\"text\":\"Turn a batch job into continuous streaming by changing the operators. \"},{\"pos\":851765,\"text\":\"<span class=\\\"t\\\">More details in Conference</span>\"},{\"pos\":865428,\"text\":\"Engine\"},{\"pos\":867255,\"text\":\"/n/ML\"},{\"pos\":869729,\"text\":\"/n/Other - deep learning, graphframes, solr, cassandra,..\"},{\"pos\":881744,\"text\":\"<span class=\\\"t\\\">Growing the community</span>\"},{\"pos\":888766,\"text\":\"New initiatives from databricks\"},{\"pos\":900467,\"text\":\"/n/The largest challenge in applying big data is the /i/skills gap/\"},{\"pos\":923184,\"text\":\"/n/StackOverflow developer survey - Spark is the top paying stack this year. \"},{\"pos\":957096,\"text\":\"<span class=\\\"t\\\">Databricks Community Edition</span>\"},{\"pos\":964828,\"text\":\"Free version of Databricks with interactive tutorials, apache spark and popular data science libraries, visualization and debug tools\"},{\"pos\":1008910,\"text\":\"<span class=\\\"t\\\">Massive open online courses</span>\"},{\"pos\":1016769,\"text\":\"Free 5 course series on big data with Apache Spark. \"},{\"pos\":1039385,\"text\":\"<span class=\\\"t\\\">Demo - Michael Armbrust</span>\"},{\"pos\":1077192,\"text\":\"I will demonstrate how you can use Apache Spark 2.0 inside of Databricks Community Edition. \"},{\"pos\":1081854,\"text\":\"/n/Log in to your personal workspace. \"},{\"pos\":1111590,\"text\":\"/n//n/Cloud based platform for running Apache Spark and doing big data analysis. \"},{\"pos\":1115616,\"text\":\"It has interactive notebooks, automatic cluster managements. \"},{\"pos\":1142723,\"text\":\"/n//n/Learning Spark and statistics can be difficult. \"},{\"pos\":1155170,\"text\":\"Our training helps with both these subjects. \"},{\"pos\":1164858,\"text\":\"These are interactive workbooks with explanations and code examples you can run in your browser. \"},{\"pos\":1182428,\"text\":\"/n//n/Let us import a lesson. \"},{\"pos\":1189015,\"text\":\"You can read the explanations, and to run any of the code snippets, you can hit SHIFT+ENTER. \"},{\"pos\":1203860,\"text\":\"/n//n/I can edit the text to test my understanding of Spark. \"},{\"pos\":1225069,\"text\":\"/n//n/Notebooks - we have taken a whole bunch of content of end to end examples and built them into the platform. \"},{\"pos\":1237340,\"text\":\"/n//n/I will start with an analysis of 2016 elections. \"},{\"pos\":1250006,\"text\":\"The notebook takes data from the Twitter stream and it graphs over time how often certain candidates are mentioned. \"},{\"pos\":1258543,\"text\":\"/n//n/They took Spark, SparkSQL and Spark streaming and combined it into this program which will find the answer. \"},{\"pos\":1284530,\"text\":\"/n//n/Clone the notebook. \"},{\"pos\":1296562,\"text\":\"Delete existing code. \"},{\"pos\":1305371,\"text\":\"And start with Spark. \"},{\"pos\":1309686,\"text\":\"/n//n/We have the Spark session - your one stop shop for working with structured data and unstructured data, batch and streaming. \"},{\"pos\":1331632,\"text\":\"/n//n/Start by loading the dataset. Point it on JSON stored on S3. \"},{\"pos\":1375422,\"text\":\"The read interface can talk to many formats. \"},{\"pos\":1401462,\"text\":\"/n//n/Filter for the things that we care about - text and createdAt. \"},{\"pos\":1418331,\"text\":\"/n//n/I will use some markdown to explain what I am doing as I go along. \"},{\"pos\":1433857,\"text\":\"You can also add images to your markdown. \"},{\"pos\":1471157,\"text\":\"/n//n/Let us start with the window function. \"},{\"pos\":1479127,\"text\":\"You can also use it for batch. \"},{\"pos\":1502839,\"text\":\"We have grouped the tweets into hour intervals. \"},{\"pos\":1519854,\"text\":\"It is easier to assign tweets to candidates - I need to turn any single row and turn it into 0, 1, 2 or 3 rows (for each candidate) - using a higher level language like Scala over SQL. \"},{\"pos\":1537348,\"text\":\"/n//n/We use the function called explode and turn the tweet into a list of candidates. \"},{\"pos\":1593155,\"text\":\"/n//n/We have got the data in the form we want. \"},{\"pos\":1615354,\"text\":\"Now we can turn this into a table. \"},{\"pos\":1646446,\"text\":\"/n//n/Switch over the SQL while that is running. \"},{\"pos\":1654554,\"text\":\"I want to do standard SQL aggregation. \"},{\"pos\":1683128,\"text\":\"/n//n/Instead of pulling out a library, I can interactively graph these results right in the browser. \"},{\"pos\":1700633,\"text\":\"We got our temporal analysis of how the mentions of candidates changes over time. \"},{\"pos\":1708434,\"text\":\"/n//n/I want to dive into specific topics and see how they change over time. \"},{\"pos\":1725496,\"text\":\"Let us look at emails. \"},{\"pos\":1734018,\"text\":\"/n//n/How about 'feel the'?\"},{\"pos\":1744015,\"text\":\"/n//n/What about 'great again'? 'Small hands'?\"},{\"pos\":1764591,\"text\":\"/n//n/So you are saying, \\\"what about streaming\\\"? \"},{\"pos\":1788372,\"text\":\"This is the true power of structured streaming and unified API in 2.0. \"},{\"pos\":1791638,\"text\":\"All I have to do is take the same exact code I used in batch and point it at a replica of the Twitter firehose. \"},{\"pos\":1802114,\"text\":\"Now when I hit SHIFT + ENTER, its going to detect that there is a streaming part to this query plan, and instead of running a single query its going to run a lot of little queries. \"},{\"pos\":1812220,\"text\":\"Over and over again, incrementally updating the answer as new data arrives. This is an example of the continuous applications Mateis was talking about. \"},{\"pos\":1832833,\"text\":\"/n//n/The hard part of streaming is not always getting the code working - its the operational aspects of taking the code and dealing with the scale. \"},{\"pos\":1848640,\"text\":\"/n//n/Here we see a chart how we are processing the data. The chart shows the rate at which data is arriving and the rate at which data is processing. \"},{\"pos\":1857380,\"text\":\"In fact, the orange line is not good - we are falling behind. \"},{\"pos\":1867124,\"text\":\"/n//n/But we can turn on performance improvements using codegen() - actually turned on by default. \"},{\"pos\":1879601,\"text\":\"Now it is going to reoptimize the query plan for the next batch. \"},{\"pos\":1897647,\"text\":\"And as you can see, its significantly faster. \"},{\"pos\":1927057,\"text\":\"/n//n/Let us review what we did. \"},{\"pos\":1964109,\"text\":\"/n//n/The power of big data is being able to share your findings. This is the reason we built collaboration into the core of Databricks Community Platform.\"},{\"pos\":1980326,\"text\":\"/n//n/We can publish the notebook - it gives a static version of the notebook. Others can import and remix. \"}]","css":".t{font-weight:bold;}.t:before{content:\"\\A\\A\";white-space: pre;}.t:after{content:\"\\A\";white-space: pre;}","videoid":"fn3WeMZZcCk","title":"Apache Spark 2.0","duration":2021.461,"category":"Apache Spark","pageName":""}