<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Data Science PyData | VideoJots</title>

    <!-- Bootstrap Core CSS -->
    <link href="../css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="../css/1-col-portfolio.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script>
        if (document.location.hostname.search("videojots.com") !== -1) {
            (function (i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r;
                i[r] = i[r] || function () {
                            (i[r].q = i[r].q || []).push(arguments)
                        }, i[r].l = 1 * new Date();
                a = s.createElement(o),
                        m = s.getElementsByTagName(o)[0];
                a.async = 1;
                a.src = g;
                m.parentNode.insertBefore(a, m)
            })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

            ga('create', 'UA-78294929-1', 'auto');
            ga('send', 'pageview');
        }

    </script>
</head>

<body>

<!-- Page Content -->
<div class="container">
    <a class="btn btn-primary" href="../">Home</a>
    <!-- Page Heading -->
    <div class="row">
        <div class="col-lg-12">
            <h1 class="page-header">Videos about data science from PyData Conferences
            </h1>
        </div>
    </div>
    <!-- /.row -->
    <div class="row">
        <div class="col-md-7"><a href="data_science_operationalization_framework.html"><img class="img-responsive"
                                                                                            src="http://img.youtube.com/vi/Mb038zOz2fM/0.jpg"></a>
        </div>
        <div class="col-md-5"><h3>Alexander Kagoshima: A Data Science Operationalization Framework</h3><h4>5/29/2015
            [00:31:49]</h4>
            <p>In a lot of our Data Science customer engagements at Pivotal, the question comes up how to put the
                developed Data Science models into production. Usually, the code produced by the Data Scientist is a
                bunch of scripts that go from data loading over data cleansing to feature extraction and then model
                training. There is rarely much thought put into how the resulting model can be used by other pieces of
                software and this is generally not a good practice of encapsulating the Data Scientist's work for others
                to re-use.What we as Data Scientists want is to create models that drive automated decision-making but
                there is clearly a mismatch to the above way of going about Big Data projects. Considering these
                challenges, we created a small prototype for a Data Science operationalization framework. This allows
                the Data Scientist to implement a model which is exposed by the framework as a REST API for easy access
                by software developers.The difference to other predictive APIs is that this framework allows for
                automatic periodic retraining of the implemented model on incoming streaming data and is able to free
                the Data Scientist of some tedious work - like Ÿkeeping track of results for different modelling and
                feature engineering approaches, basic visualization of model performance and the creation of multiple
                model instances for different data streams. It is written by practitioning Data Scientists for Data
                Scientists.Moreover, the framework will be released this year under an Open Source license which means
                that unlike other predictive APIs which only host one instance for Data Scientists to push their models
                to, this allows Data Scientists to completely control their own model codebase. In addition, it is
                deployable on Cloud Foundry and Heroku and can thus use some features of PaaS, which means less work in
                thinking about how to deploy and scale a model in production. The model is implemented in Python and
                uses Flask to expose the REST API and the current prototype uses Redis as backend storage for the
                trained models. Models can be either custom-written or use existing Python ML libraries like
                scikit-learn. The framework is currently geared towards online learning, but it is possible to hook it
                up to a Spark backend to realize model training in batch on large datasets.

                Alexander Kagoshima</p><a class="btn btn-primary" href="data_science_operationalization_framework.html">View
                Outline<span class="glyphicon glyphicon-chevron-right"></span></a></div>
    </div>
    <hr>
    <!-- Project One -->
    <div class="row">
        <div class="col-md-7"><a href="sports_analytics.html"><img class="img-responsive"
                                                                   src="http://img.youtube.com/vi/ntw6HgflqtM/0.jpg"></a>
        </div>
        <div class="col-md-5"><h3>Peadar Coyle: Probabilistic Programming in Sports Analytics</h3><h4>5/30/2015
            [00:23:43]</h4>
            <p>Probabilistic Programming and Bayesian Methods are called by some a new paradigm. There are numerous
                interesting applications such as to Quantitative Finance.I'll discuss what probabilistic programming is,
                why should you care and how to use PyMC and PyMC3 from Python to implement these methods. I'll be
                applying these methods to studying the problem of 'rugby sports analytics' particularly how to model the
                winning team in the recent Six Nations in Rugby. I will discuss the framework and how I was able to
                quickly and easily produce an innovative and powerful model as a non-expert.

                Peadar Coyle</p><a class="btn btn-primary" href="sports_analytics.html">View Outline<span
                    class="glyphicon glyphicon-chevron-right"></span></a></div>
    </div>
    <hr>
    <div class="row">
        <div class="col-md-7"><a href="web_text_scraping_and_mining.html"><img class="img-responsive"
                                                                               src="http://img.youtube.com/vi/ikxm_kFL9MA/0.jpg"></a>
        </div>
        <div class="col-md-5"><h3>Brian Carter: Lifecycle of Web Text Mining: Scrape to Sense</h3><h4>5/30/2015
            [00:27:54]</h4>
            <p>Pillreports.net is an on-line database of reviews of Ecstasy pills. In consumer theory illicit drugs are
                experience goods, in that the contents are not known until the time of consumption. Websites like
                Pillreports.net, may be viewed as an attempt to bridge that gap, as well as highlighting instances,
                where a particular pill is producing undesirable effects. This talk will present the experiences and
                insights from a text mining project using data scraped from the Pillreports.net site.The setting up and
                the benefits, ease of using BeautifulSoup package and pymnogo to store the data in MongoDB will be
                outlined.A brief overview of some interesting parts of data cleansing will be detailed.Insights and
                understanding of the data gained from applying classification and clustering techniques will be
                outlined. In particular visualizations of decision boundaries in classification using "most important
                variables". Similarly visualizations of PCA projections for understanding cluster separation will be
                detailed to illustrate cluster separation. The talk will be presented in the iPython notebook and all
                relevant datasets and code will be supplied. Python Packages Used: (bs4, matplotlib, nltk, numpy,
                pandas, re, seaborn, sklearn, scipy, urllib2)

                Brian Carter</p><a class="btn btn-primary" href="web_text_scraping_and_mining.html">View Outline<span
                    class="glyphicon glyphicon-chevron-right"></span></a></div>
    </div>
    <hr>
    <div class="row">
        <div class="col-md-7"><a href="motion_prediction.html"><img class="img-responsive"
                                                                    src="http://img.youtube.com/vi/xVC9naY4LsQ/0.jpg"></a>
        </div>
        <div class="col-md-5"><h3>Paul Balzer: Running, walking, sitting or biking? - Motion prediction with
            acceleration and rotation</h3><h4>5/29/2015 [00:22:20]</h4>
            <p>A lot of devices can measure acceleration and rotationrates. With the right features, Machine Learning
                can predict, weather you are sitting, running, walking or going by bike. This talk will show you, how to
                calculate features with Pandas and set up a real time classifier with SciKit-Learn. Including hardware
                demo.

                Paul Balzer</p><a class="btn btn-primary" href="motion_prediction.html">View Outline<span
                    class="glyphicon glyphicon-chevron-right"></span></a></div>
    </div>
    <hr>
    <div class="row">
        <div class="col-md-7"><a href="python_optimization_lessons.html"><img class="img-responsive"
                                                                              src="http://img.youtube.com/vi/vU4TlwZzTfU/0.jpg"></a>
        </div>
        <div class="col-md-5"><h3>Radim Řehůřek - Faster than Google? Optimization lessons in Python.</h3><h4>7/27/2014
            [00:27:30]</h4>
            <p>View slides for this presentation here:
                http://www.slideshare.net/PyData/radim-ehek

                PyData Berlin 2014
                Lessons from translating Google's deep learning algorithm into Python. Can a Python port compete with
                Google's tightly optimized C code? Spoiler: making use of Python and its vibrant ecosystem (generators,
                NumPy, Cython...), the optimized Python port is cleaner, more readable and clocks in—somewhat
                astonishingly—4x faster than Google's C. This is 12,000x faster than a naive, pure Python implementation
                and 100x faster than an optimized NumPy implementation. The talk will go over what went well (data
                streaming to process humongous datasets, parallelization and avoiding GIL with Cython, plugging into
                BLAS) as well as trouble along the way (BLAS idiosyncrasies, Cython issues, dead ends). The quest is
                also documented on my blog.</p><a class="btn btn-primary" href="python_optimization_lessons.html">View
                Outline<span class="glyphicon glyphicon-chevron-right"></span></a></div>
    </div>
    <hr>
    <!-- Footer -->
    <footer>
        <div class="row">
            <div class="col-lg-12">
                <p>Copyright &copy; VideoJots 2016</p>
            </div>
        </div>
        <!-- /.row -->
    </footer>

</div>
<!-- /.container -->

<!-- jQuery -->
<script src="../js/jquery.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="../js/bootstrap.min.js"></script>

</body>

</html>
